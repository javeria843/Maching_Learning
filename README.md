# 🚀 Machine Learning Practice – Titanic Dataset & Ensemble Learning  

This repository contains my hands-on practice with **Machine Learning models** using the famous **Titanic Dataset**.  
The goal is to predict passenger survival and explore how different ML models and **Ensemble Learning techniques** (Bagging & Boosting) improve performance.  

---

## 📌 Features
- Data preprocessing with **Pandas** & **Scikit-learn**  
- Train-test split & feature scaling  
- Implementation of ML models (Logistic Regression, Decision Tree, etc.)  
- **Ensemble Learning**:
  - ✅ Bagging (Random Forest Classifier)  
  - ✅ Boosting (AdaBoost Classifier)  

---

## 📂 Repository Structure
📦 Machine_Learning
┣ 📜 Lab_Task_ML.ipynb # Titanic dataset preprocessing & model training
┣ 📜 Decision_Tree_classifier.ipynb
┣ 📜 Ensemble_learning.ipynb # Bagging & Boosting implementation
┣ 📜 lab03_simple_linear_regression.ipynb
┣ 📜 Lab_3_Multivariate_Linear_Regression.ipynb

---

## ⚙️ How to Run
1. Clone the repo:
   ```bash
   git clone https://github.com/javeria843/Maching_Learning.git
   cd Maching_Learning
🏷 Key Concepts

Bagging (Bootstrap Aggregating):
Trains multiple models on random subsets of data in parallel to reduce variance. Example: Random Forest 🌲

Boosting:
Trains models sequentially, each correcting errors of the previous one to reduce bias. Example: AdaBoost ⚡

📢 Connect with Me

If you’re interested in ML & Data Science, let’s connect on LinkedIn
https://www.linkedin.com/in/javeriaiqbalai/
